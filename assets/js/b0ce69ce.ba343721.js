"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[22],{16008:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>i,toc:()=>l});var i=t(98955),s=t(74848),r=t(28453);const a={title:"Building a RAG System with PostgreSQL, pgvector, SQLAlchemy, and Gemma/Gemini Embeddings",slug:"building-a-rag-system-with-postgresql-pgvector-sqlalchemy-gemma-gemini-embeddings",description:"In this post, we build a Retrieval-Augmented Generation (RAG) pipeline from the ground up. Starting with synthetic data generated by Gemini, we create embeddings with both Gemini and Gemma, store them in PostgreSQL with pgvector, and query them through SQLAlchemy. We also visualize the embedding space interactively to reveal semantic structure. Along the way, we demonstrate how semantic search goes beyond keywords and showcase a multi-agent system that automates dataset generation.",authors:["haruiz"],image:"https://haruiz.github.io/img/building-a-rag-system-with-postgresql-pgvector-sqlalchemy-gemma-gemini-embeddings.png",tags:["RAG","data-science"]},o=void 0,d={authorsImageUrls:[void 0]},l=[{value:"A Hands-On Example: Recipe-Based RAG",id:"a-hands-on-example-recipe-based-rag",level:3},{value:"Workflow Overview",id:"workflow-overview",level:3},{value:"Hands-On Tutorial",id:"hands-on-tutorial",level:2},{value:"Pipeline Overview",id:"pipeline-overview",level:4},{value:"1. Generate a Synthetic Recipe Dataset",id:"1-generate-a-synthetic-recipe-dataset",level:2},{value:"2. Compute Gemini and Gemma embeddings",id:"2-compute-gemini-and-gemma-embeddings",level:2},{value:"Compute embeddings with Gemini",id:"compute-embeddings-with-gemini",level:3},{value:"Compute embeddings with Gemma",id:"compute-embeddings-with-gemma",level:3},{value:"Key Features",id:"key-features",level:4},{value:"3. Implement vector store with PostgreSQL and pgvector",id:"3-implement-vector-store-with-postgresql-and-pgvector",level:2},{value:"Why pgvector + SQLAlchemy?",id:"why-pgvector--sqlalchemy",level:4},{value:"4. Query the RAG System",id:"4-query-the-rag-system",level:2},{value:"5. Visualizing Recipe Embeddings",id:"5-visualizing-recipe-embeddings",level:2},{value:"Dimensionality Reduction",id:"dimensionality-reduction",level:3},{value:"Interactive Plot",id:"interactive-plot",level:3},{value:"Bonus: Automating Synthetic Data Generation with a Multi-Agent Architecture",id:"bonus-automating-synthetic-data-generation-with-a-multi-agent-architecture",level:2},{value:"The Idea",id:"the-idea",level:3},{value:"Workflow Overview",id:"workflow-overview-1",level:3},{value:"Core Components",id:"core-components",level:3},{value:"Example: Running the Pipeline",id:"example-running-the-pipeline",level:3},{value:"Conclusion &amp; Closing Remarks",id:"conclusion--closing-remarks",level:2},{value:"References",id:"references",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"Embedding models are the backbone of modern search and Retrieval-Augmented Generation (RAG) systems. They offer a machine learning-based approach to encode multimodal data\u2014such as text, code, images, and audio\u2014into dense, high-dimensional vector representations that preserve semantic meaning. In this vector space, each data point is represented as a numerical vector, and items with similar meanings naturally cluster together. This allows systems to search, rank, and reason based on meaning, rather than relying on brittle string matches or exact keyword overlap."}),"\n",(0,s.jsx)(n.p,{children:"This semantic representation unlocks smarter retrieval pipelines and more reliable, grounded generative answers, which are critical for building scalable and trustworthy AI applications across domains."}),"\n",(0,s.jsx)(n.p,{children:"Embedding models power a wide range of real-world applications, including:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Semantic Search"}),": Retrieve content that matches the ",(0,s.jsx)(n.em,{children:"intent"})," of a query\u2014even if the words are different. Perfect for document search, Q&A systems, and internal knowledge bases."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Retrieval-Augmented Generation (RAG)"}),": Fetch the most relevant context to ground large language models, improving factual accuracy and traceability in generated responses."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Recommendation Systems"}),": Recommend similar items\u2014articles, videos, products\u2014based on shared meaning rather than manual tagging or exact history."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Clustering and Topic Modeling"}),": Group related items together to uncover patterns, trends, and themes in large datasets (e.g., customer feedback or scientific publications)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Deduplication and Near-Duplicate Detection"}),": Identify redundant or highly similar entries that simple string comparisons would miss."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cross-Lingual Retrieval"}),": Match content across different languages using shared multilingual vector spaces\u2014critical for global applications."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Anomaly Detection"}),": Spot outliers based on distance from \u201cnormal\u201d behavior in embedding space, useful in fraud detection or monitoring systems."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Intent Routing and Tool Selection"}),": Embed user queries and route them to the appropriate models, APIs, or workflows based on semantic similarity."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"a-hands-on-example-recipe-based-rag",children:"A Hands-On Example: Recipe-Based RAG"}),"\n",(0,s.jsxs)(n.p,{children:["In this post, we\u2019ll put embeddings to work with a hands-on example that shows how they make RAG possible end to end. Specifically, we are building a ",(0,s.jsx)(n.strong,{children:"recipe-focused Retrieval-Augmented Generation (RAG) pipeline"}),", powered by a synthetic dataset generated with Gemini. Recipes provide a familiar yet structured domain that makes it easy to showcase how semantic search goes beyond traditional keyword-based approaches."]}),"\n",(0,s.jsxs)(n.p,{children:["Unlike simple keyword queries, this system allows you to explore recipes by ",(0,s.jsx)(n.strong,{children:"semantic meaning"}),". That means you can:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Find dishes with similar ingredients or preparation styles"}),"\n",(0,s.jsx)(n.li,{children:"Filter by preparation time"}),"\n",(0,s.jsx)(n.li,{children:"Search by country of origin"}),"\n",(0,s.jsx)(n.li,{children:"Retrieve recipes that include specific ingredients"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"We\u2019ll:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Generate a synthetic corpus with Gemini (recipe dataset)."}),"\n",(0,s.jsx)(n.li,{children:"Create embeddings using both Gemini and Gemma."}),"\n",(0,s.jsx)(n.li,{children:"Store embeddings in PostgreSQL with pgvector."}),"\n",(0,s.jsx)(n.li,{children:"Perform semantic retrieval using cosine similarity."}),"\n",(0,s.jsx)(n.li,{children:"Build a retrieval-augmented generation (RAG) pipeline tailored to recipes."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"(Optional)"})," Evaluate retrieval effectiveness and visualize the embedding space interactively."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"workflow-overview",children:"Workflow Overview"}),"\n",(0,s.jsx)(n.p,{children:"The journey from raw text to queryable embeddings follows this pipeline:"}),"\n",(0,s.jsx)(n.mermaid,{value:"flowchart LR\n    A[Text Data] --\x3e B[Embedding Model]\n    B --\x3e C[Embeddings / Vectors]\n    C --\x3e D[(PostgreSQL + pgvector)]\n    D --\x3e E[SQLAlchemy Query<br/>Similarity Search]"}),"\n",(0,s.jsxs)(n.p,{children:["Here, raw text is transformed into embeddings, stored in PostgreSQL with pgvector, and later retrieved through similarity search. This storage and retrieval layer grounds our RAG pipeline, ensuring that generative models work with ",(0,s.jsx)(n.strong,{children:"relevant, semantically aligned context"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"hands-on-tutorial",children:"Hands-On Tutorial"}),"\n",(0,s.jsx)(n.p,{children:"With the high-level pipeline and background covered, it\u2019s time to move from theory into practice. We\u2019ll begin with some boilerplate code\u2014covering the essential imports, a few utility constants, and the schema definition."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import asyncio\nimport functools\nimport logging\nimport os\nimport time\nfrom typing import Any, AsyncGenerator, Sequence\nfrom typing import Optional\n\nimport kagglehub\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport torch\nimport umap.umap_ as umap\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom google.genai.types import SingleEmbedContentResponse, InlinedEmbedContentResponse\nfrom pgvector.sqlalchemy import Vector\nfrom pydantic import BaseModel\nfrom pydantic_settings import BaseSettings\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sqlalchemy import Column, Integer, String, insert, select, Row\nfrom sqlalchemy import URL\nfrom sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker\nfrom sqlalchemy.orm import DeclarativeBase\nfrom sqlalchemy.orm import registry\nfrom sqlalchemy.sql import text\n\n\n# Set up logging\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\n# Disable parallelism in tokenizers to avoid warnings\nos.environ["TOKENIZERS_PARALLELISM"] = "False"\n# Load environment variables from a .env file\nload_dotenv(dotenv_path="dev.env")\n\nclass Recipe(BaseModel):\n    recipe_name: str\n    description: str\n    ingredients: list[str]\n    time_minutes: int\n    country: str\n\n# Define constants and initialize the GenAI client\nclient = genai.Client()\nEMBED_DIM=768\nSYNTHETIC_DATASET_FILE = "./recipes.csv"\nEMBEDDING_DATASET_FILE = "./recipes_with_embeddings.parquet"\nMODEL_NAME = "gemini-2.5-pro"\nGEMMA_EMBEDDING_MODEL = "google/embeddinggemma/transformers/embeddinggemma-300m"\nGEMINI_EMBEDDING_MODEL = "gemini-embedding-001"\n\ndef timeit(func):\n  """A decorator to measure the execution time of an async function."""\n  if not asyncio.iscoroutinefunction(func):\n    raise TypeError("timeit decorator can only be used with async functions")\n\n  @functools.wraps(func)\n  async def wrapper(*args, **kwargs):\n    start = time.perf_counter()\n    result = await func(*args, **kwargs)\n    end = time.perf_counter()\n    logger.info(f"{func.__name__} took {end - start:.4f} seconds")\n    return result\n\n  return wrapper\n\n# Utility function to parse fields content as and string\ndef _as_str(x) -> str:\n  """Robustly stringifies an object, handling lists, tuples, sets, and None."""\n  if x is None:\n    return ""\n  if isinstance(x, (list, tuple, set)):\n    return ", ".join(map(str, x))\n  return str(x)\n\n'})}),"\n",(0,s.jsx)(n.p,{children:"Once the groundwork is set, we can move on to the setup pipeline itself\u2014starting with data generation, continuing with embedding creation, and finishing with database setup for storage and retrieval."}),"\n",(0,s.jsx)(n.h4,{id:"pipeline-overview",children:"Pipeline Overview"}),"\n",(0,s.jsx)(n.mermaid,{value:"flowchart TD\n    A[create_synthetic_dataset] --\x3e B[create_embeddings]\n    B --\x3e C[ensure_database]\n    C --\x3e D[ensure_extensions]\n    D --\x3e E[create_tables]\n    E --\x3e F[create_indexes]\n    F --\x3e G[populate_db]"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Pipeline function"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def setup() -> None:\n    """Runs the full data pipeline: create dataset, embeddings, and set up the database."""\n    create_synthetic_dataset(n=200)\n    create_embeddings()\n    await ensure_database()\n    await ensure_extensions()\n    await create_tables()\n    await create_indexes()\n    await populate_db()\n'})}),"\n",(0,s.jsxs)(n.p,{children:["In the previous code the ",(0,s.jsx)(n.code,{children:"setup()"})," function orchestrates the entire pipeline, from generating data to populating the database. Here\u2019s what happens at each step:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"create_synthetic_dataset(n=200)"})}),"\nGenerates a synthetic dataset of 200 examples that we will use throughout the pipeline. This provides the raw text data needed to build embeddings."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"create_embeddings()"})}),"\nTransforms the dataset into vector representations (embeddings) using our embedding model. These embeddings capture semantic meaning and will later be stored in the database."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"await ensure_database()"})}),"\nVerifies that the PostgreSQL database exists and is accessible. If not, it creates the database to ensure the rest of the pipeline can run smoothly."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"await ensure_extensions()"})}),"\nThis step ensures that the pgvector extension is installed and enabled in our PostgreSQL instance. The pgvector extension adds support for vector datatypes, which are not natively available in PostgreSQL. Without it, we wouldn\u2019t be able to store or query embeddings efficiently."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Specifically, pgvector provides:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A dedicated vector column type for storing embeddings as arrays of floats."}),"\n",(0,s.jsx)(n.li,{children:"Built-in functions for computing similarity and distance metrics, such as cosine similarity, Euclidean distance, and inner product."}),"\n",(0,s.jsx)(n.li,{children:"Support for indexing methods (e.g., IVF, HNSW) that accelerate similarity searches across large embedding collections."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"await create_tables()"})}),"\nCreates the necessary tables in the database using SQLAlchemy models. This step defines the schema for storing both metadata and embeddings."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"await create_indexes()"})}),"\nAdds vector indexes (such as IVF or HNSW, depending on the configuration) to speed up similarity search queries against the stored embeddings."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"await populate_db()"})}),"\nInserts the dataset and its embeddings into the database, making them available for retrieval and search operations."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"1-generate-a-synthetic-recipe-dataset",children:"1. Generate a Synthetic Recipe Dataset"}),"\n",(0,s.jsx)(n.p,{children:"This is the first step in our pipeline: we\u2019ll start by generating a synthetic corpus to work with. Instead of manually collecting recipes, we\u2019ll leverage Gemini\u2019s reasoning capabilities along with the API\u2019s support for structured outputs to automatically produce a DataFrame containing 200 unique recipes from around the world. This dataset will then be exported to a CSV file, which we\u2019ll use later when computing embeddings."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def create_synthetic_dataset(n: int = 100) -> None:\n  """Uses Gemini to create a synthetic dataset of recipes and saves it as a CSV file.\n\n  Args:\n      n: The number of unique recipes to generate.\n  """\n\n  prompt_for_synthetic_data = f"""\n    Generate a list of unique recipes from around the world:\n    \n    Requirements:\n    - Exactly {n} UNIQUE recipes.\n    - Each recipe must include: recipe_name, description, ingredients (array of strings), time_minutes (int), country (string), preparation (string).\n    - Use a variety of countries/regions. Avoid duplicates by recipe_name.\n    """\n  response = client.models.generate_content(\n    model=MODEL_NAME,\n    contents=types.Part.from_text(text=prompt_for_synthetic_data),\n    config= types.GenerateContentConfig(\n      response_mime_type="application/json",\n      response_schema=list[Recipe],\n      thinking_config = types.ThinkingConfig(\n        include_thoughts=True\n      )\n    )\n  )\n  \n  structured_output = response.parsed\n  df = pd.DataFrame([item.model_dump() for item in structured_output])\n  df.to_csv(SYNTHETIC_DATASET_FILE, index=False)\n  logger.info(f"Synthetic dataset created and saved to {SYNTHETIC_DATASET_FILE}  with {len(df)} records.")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"2-compute-gemini-and-gemma-embeddings",children:"2. Compute Gemini and Gemma embeddings"}),"\n",(0,s.jsx)(n.p,{children:"Next, we enrich our synthetic dataset by adding two new columns: one with Gemini embeddings and another with Gemma embeddings. To do this, we\u2019ll take the recipe descriptions\u2014along with a few other key fields\u2014and turn them into vector representations using the embedding models. Think of embeddings like placing each recipe as a point on a map, where similar recipes end up closer together. These \u201cmap coordinates\u201d are what will power our RAG (Retrieval-Augmented Generation) semantic search system, helping it find and connect information by meaning, not just keywords."}),"\n",(0,s.jsxs)(n.p,{children:["Although Gemma Embeddings were designed as a lighter alternative\u2014optimized for on-device AI\u2014they draw significant inspiration from the Gemini architecture in their implementation. To just mention a case, Both models share a common foundation, having been trained with Matryoshka Representation Learning (MRL), a technique that makes embeddings more flexible and efficient. Out of curiosity (and not as a strict benchmark), we\u2019ll compare Gemini\u2019s embeddings side by side with Gemma\u2019s open-weights version. To keep the comparison fair, we configured the ",(0,s.jsx)(n.code,{children:"gemini-embedding-001"})," model to produce vectors with a dimensionality of 768."]}),"\n",(0,s.jsx)(n.p,{children:"here is the code:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def create_embeddings(limit: Optional[int] = None) -> None:\n    """Reads the synthetic dataset, generates embeddings, and saves the result to a Parquet file.\n\n    This function reads the `recipes.csv` file, constructs a unified text field for each\n    recipe, and then generates embeddings using both Gemini and Gemma models. The resulting\n    DataFrame, including the new embedding columns, is saved to a Parquet file.\n\n    Args:\n        limit: An optional integer to limit the number of rows processed from the\n               input CSV. Useful for testing.\n    """\n\n    df = pd.read_csv(SYNTHETIC_DATASET_FILE)\n    if limit:\n        df = df.head(limit).copy()\n\n    # Build the unified text field\n    df["text"] = df.apply(\n        lambda row: (\n            f"Recipe: {_as_str(row.get(\'recipe_name\'))}.\\n"\n            f"Description: {_as_str(row.get(\'description\'))}.\\n"\n            f"Ingredients: {_as_str(row.get(\'ingredients\'))}.\\n"\n            f"Country: {_as_str(row.get(\'country\'))}.\\n"\n            f"Time to prepare: {_as_str(row.get(\'time_minutes\'))} minutes."\n        ),\n        axis=1\n    )\n\n    texts = df["text"].tolist()\n    # Compute embeddings only if missing\n    if "gemini_embedding" not in df.columns or df["gemini_embedding"].isna().any():\n        df["gemini_embedding"] = get_gemini_embeddings(texts)\n    if "gemma_embedding" not in df.columns or df["gemma_embedding"].isna().any():\n        df["gemma_embedding"] = get_gemma_embeddings(texts)\n\n    df.to_parquet(EMBEDDING_DATASET_FILE, index=False, engine="pyarrow")\n    logger.info(f"Embeddings created and saved to {EMBEDDING_DATASET_FILE} with {len(df)} records.")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"compute-embeddings-with-gemini",children:"Compute embeddings with Gemini"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Gemini API"})," provides text embedding models capable of generating embeddings for words, phrases, sentences, and even code. These embeddings serve as a foundation for advanced NLP tasks such as semantic search, classification, and clustering, delivering more accurate and context-aware results than traditional keyword-based methods."]}),"\n",(0,s.jsxs)(n.p,{children:["You can apply embeddings across a wide range of tasks, including ",(0,s.jsx)(n.strong,{children:"semantic similarity"}),", ",(0,s.jsx)(n.strong,{children:"classification"}),", and ",(0,s.jsx)(n.strong,{children:"clustering"}),". For the complete list of supported task types, see the ",(0,s.jsx)(n.a,{href:"https://ai.google.dev/gemini-api/docs/embeddings#supported-task-types",children:"Supported task types table"}),". Choosing the appropriate task type helps optimize the embeddings for your specific use case, improving both accuracy and efficiency."]}),"\n",(0,s.jsxs)(n.p,{children:["You can adjust the size of the embedding vector with the ",(0,s.jsx)(n.code,{children:"output_dimensionality"})," parameter. Smaller dimensions reduce storage requirements and speed up downstream computations, while typically sacrificing little in quality. By default, embeddings are ",(0,s.jsx)(n.strong,{children:"3072-dimensional"}),", but recommended options include ",(0,s.jsx)(n.strong,{children:"768"}),", ",(0,s.jsx)(n.strong,{children:"1536"}),", or ",(0,s.jsx)(n.strong,{children:"3072"}),"."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["The ",(0,s.jsx)(n.strong,{children:"3072-dimensional"})," embeddings are normalized by default, making them ideal for semantic similarity tasks since they rely on comparing vector directions rather than magnitudes."]}),"\n",(0,s.jsx)(n.li,{children:"For other dimensions (e.g., 768 or 1536), you\u2019ll need to apply normalization yourself before using them for similarity comparisons."}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["The Gemini embedding model, ",(0,s.jsx)(n.code,{children:"gemini-embedding-001"}),", is trained using ",(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/2205.13147",children:"Matryoshka Representation Learning (MRL)"}),". This method enables the model to produce high-dimensional vectors where the initial components/dimensions (the prefixes) capture the most important information. As a result, we can truncate the original large embedding\u2014typically to 512 or 768 dimensions\u2014while still preserving most of its semantic content. This approach makes embeddings more flexible: it provides full detail when necessary and lighter, faster representations for efficiency. For more details check: ",(0,s.jsx)(n.a,{href:"https://huggingface.co/blog/matryoshka#why-would-you-use-%F0%9F%AA%86-matryoshka-embedding-models",children:"Introduction to Matryoshka Embedding Models"})]})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def get_gemini_embeddings(texts: list[str]) -> list[list[float]]:\n    """Computes embeddings for a list of texts using the Gemini Embedding model in batch mode.\n\n    This function sends a batch embedding request to the Gemini API. It\'s suitable for\n    processing a large number of documents at once, which is more efficient than sending\n    one request per document. The function will poll the API until the batch job is\n    completed and then return the resulting embeddings.\n\n    Args:\n        texts: A list of strings to embed.\n\n    Returns:\n        A list of embeddings, where each embedding is a list of floats.\n\n    Raises:\n        RuntimeError: If the batch embedding job fails.\n    """\n    # Create a batch embedding job request. This sends all texts to the API at once.\n    batch_job = client.batches.create_embeddings(\n        # Specify the model to use for generating embeddings.\n        model=GEMINI_EMBEDDING_MODEL,\n        # Define the source of the texts to be embedded. Here, we use an in-memory list.\n        src=types.EmbeddingsBatchJobSource(\n            # `inlined_requests` is used for providing the data directly in the request.\n            inlined_requests=types.EmbedContentBatch(\n                # Convert each text string into a `Part` object for the API.\n                contents=[types.Part.from_text(text=text) for text in texts],\n                # Configure the embedding task.\n                config=types.EmbedContentConfig(\n                    # `RETRIEVAL_DOCUMENT` is optimized for texts that will be stored and retrieved.\n                    task_type="RETRIEVAL_DOCUMENT",\n                    # Specify the desired dimension for the output embedding vectors.\n                    output_dimensionality=EMBED_DIM\n                )\n            )\n        ),\n        # Configure the batch job itself, giving it a display name for identification.\n        config=types.CreateEmbeddingsBatchJobConfig(\n            display_name="embedding-batch-job"\n        )\n    )\n    # Log the name of the created batch job for tracking.\n    logging.info(f"Created batch job: {batch_job.name}")\n    # Define the set of states that indicate the job has finished.\n    completed_states = {\'JOB_STATE_SUCCEEDED\', \'JOB_STATE_FAILED\', \'JOB_STATE_CANCELLED\', \'JOB_STATE_EXPIRED\'}\n\n    # Get the unique name of the job to use for polling.\n    job_name = batch_job.name\n    logger.info(f"Polling status for job: {job_name}")\n    # Fetch the initial status of the batch job.\n    batch_job = client.batches.get(name=job_name)  # Initial get\n    # Loop and poll the job status until it reaches a completed state.\n    while batch_job.state.name not in completed_states:\n        logger.info(f"Current state: {batch_job.state.name}")\n        # Wait for 30 seconds before checking the status again to avoid excessive polling.\n        time.sleep(30)  # Wait for 30 seconds before polling again\n        batch_job = client.batches.get(name=job_name)\n\n    logger.info(f"Job finished with state: {batch_job.state.name}")\n    # If the job failed, raise an error with the details.\n    if batch_job.state.name == \'JOB_STATE_FAILED\':\n        raise RuntimeError(f"Batch job failed: {batch_job.error}")\n\n    # Initialize an empty list to store the final embeddings.\n    embeddings = []\n    # Check if the job destination contains the inlined responses.\n    if batch_job.dest and batch_job.dest.inlined_embed_content_responses:\n        # Iterate through each response in the completed batch job.\n        for content_response in batch_job.dest.inlined_embed_content_responses:\n            content_response: InlinedEmbedContentResponse\n            # If a specific text failed to embed, log the error and append an empty list.\n            if content_response.error:\n                logging.error(f"Error in content response: {content_response.error}")\n                embeddings.append([])\n                continue\n            # Extract the successful embedding response.\n            embed_response: SingleEmbedContentResponse = content_response.response\n            # Append the embedding values (a list of floats) to our results.\n            embeddings.append(embed_response.embedding.values)\n    return embeddings\n'})}),"\n",(0,s.jsx)(n.h3,{id:"compute-embeddings-with-gemma",children:"Compute embeddings with Gemma"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"EmbeddingGemma"})," is a 308M-parameter multilingual text embedding model built on Gemma 3. It is designed to run efficiently on consumer hardware such as phones, laptops, and tablets, while still delivering strong performance on a wide range of language tasks."]}),"\n",(0,s.jsxs)(n.p,{children:["At its core, the model produces ",(0,s.jsx)(n.strong,{children:"numerical representations of text"})," that can be applied to downstream tasks including information retrieval, semantic similarity search, classification, and clustering."]}),"\n",(0,s.jsx)(n.h4,{id:"key-features",children:"Key Features"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multilingual support"}),": Trained on over 100 languages to provide broad linguistic coverage."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Flexible output dimensions"}),": Supports dimensionality from 768 down to 128 using Matryoshka Representation Learning (MRL), enabling a tradeoff between speed, storage, and accuracy."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"2K token context window"}),": Handles long text inputs and documents directly on-device."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Storage efficiency"}),": Runs in under 200MB of RAM when quantized, making it suitable for resource-constrained environments."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Low latency"}),": Generates embeddings in less than 22ms on EdgeTPU, enabling fast and responsive applications."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Offline and secure"}),": Operates without an internet connection, ensuring sensitive data remains private on the device."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"EmbeddingGemma brings high-quality, multilingual text understanding directly to personal hardware. This makes it possible to build applications that are not only fast and efficient but also secure and reliable\u2014without requiring constant cloud connectivity."}),"\n",(0,s.jsxs)(n.p,{children:["For more information, check the official documentation @ ",(0,s.jsx)(n.a,{href:"https://ai.google.dev/gemma/docs/embeddinggemma",children:"EmbeddingGemma model overview"})]}),"\n",(0,s.jsx)(n.p,{children:"In the following function, we use the Sentence-Transformers library, which offers a high-level API for working with embedding models:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def get_gemma_embeddings(texts: list[str]) -> list[list[float]]:\n  """Computes embeddings for a list of texts using a local Gemma model.\n  \n  This function uses the `sentence-transformers` library to load a pre-trained\n  Gemma embedding model from Kaggle Hub. It automatically uses a CUDA-enabled GPU\n  if available, otherwise, it falls back to the CPU. It then encodes the provided\n  list of texts into embedding vectors.\n  \n  Args:\n      texts: A list of strings to embed.\n  \n  Returns:\n      A list of embeddings, where each embedding is a list of floats.\n  """\n  # Determine the computation device: \'cuda\' for GPU if available, otherwise \'cpu\'.\n  device = "cuda" if torch.cuda.is_available() else "cpu"\n  # Download the Gemma model from Kaggle Hub and get the local path.\n  model_id = kagglehub.model_download(GEMMA_EMBEDDING_MODEL)\n  # Load the pre-trained SentenceTransformer model and move it to the selected device.\n  model = SentenceTransformer(model_id).to(device=device)\n  # Encode the list of texts into embedding vectors.\n  candidate_embeddings = model.encode(texts)\n  # Convert the resulting numpy array of embeddings to a standard Python list of lists.\n  return candidate_embeddings.tolist()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"3-implement-vector-store-with-postgresql-and-pgvector",children:"3. Implement vector store with PostgreSQL and pgvector"}),"\n",(0,s.jsxs)(n.p,{children:["To proceed with the implementation of our ",(0,s.jsx)(n.strong,{children:"RAG (Retrieval-Augmented Generation) system"}),", we need a reliable way to make embeddings useful in practice. Storing them as raw arrays in memory works for quick experiments, but quickly breaks down when scaling to thousands or millions of vectors."]}),"\n",(0,s.jsxs)(n.p,{children:["This is where ",(0,s.jsx)(n.strong,{children:"pgvector"})," comes in\u2014a PostgreSQL extension that enables efficient vector similarity search. With pgvector, we can store embeddings directly inside a relational database and query them using familiar SQL syntax. This makes it possible to combine ",(0,s.jsx)(n.strong,{children:"semantic search"})," with ",(0,s.jsx)(n.strong,{children:"structured relational data"}),", opening the door to richer applications."]}),"\n",(0,s.jsx)(n.h4,{id:"why-pgvector--sqlalchemy",children:"Why pgvector + SQLAlchemy?"}),"\n",(0,s.jsx)(n.p,{children:"In this section, we\u2019ll set up a vector store with pgvector and connect it to our application. To simplify database interactions, we\u2019ll use SQLAlchemy, which provides a clean Pythonic interface for working with PostgreSQL. With SQLAlchemy, we can define schemas as Python classes, manage migrations, and write maintainable queries\u2014all while seamlessly integrating pgvector\u2019s custom vector column types."}),"\n",(0,s.jsx)(n.p,{children:"By combining pgvector with SQLAlchemy, we get the best of both worlds: efficient vector similarity search within PostgreSQL, and a scalable, developer-friendly abstraction layer that makes the pipeline easier to build, extend, and maintain in production."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Database and SQLAlchemy setup"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class DbSettings(BaseSettings):\n    DB_HOST: str = "localhost"\n    DB_PORT: int = 5432\n    DB_NAME: str = "recipesdb"\n    DB_USER: str = "<postgres user>"\n    DB_PASSWORD: str = "<postgres user password>"\n\nsettings = DbSettings()\n\n\ndb_url = URL.create(\n    drivername="postgresql+asyncpg",\n    username=settings.DB_USER,\n    password=settings.DB_PASSWORD,  # URL.create safely quotes special chars\n    host=settings.DB_HOST,\n    port=settings.DB_PORT,\n    database=settings.DB_NAME,\n)\n\nengine = create_async_engine(db_url, pool_pre_ping=True)\nSessionLocal = async_sessionmaker(engine, expire_on_commit=False, class_=AsyncSession)\nmapper_registry = registry()\n\n\nclass Base(DeclarativeBase):\n    registry = mapper_registry\n\n\nclass RecipeORM(Base):\n    __tablename__ = "recipes"\n\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    recipe_name = Column(String, index=True)\n    description = Column(String)\n    ingredients = Column(String)  # Store as a comma-separated string\n    preparation = Column(String)\n    time_minutes = Column(Integer)\n    country = Column(String)\n    gemini_embedding = Column(Vector(EMBED_DIM))\n    gemma_embedding = Column(Vector(EMBED_DIM))\n\n\nasync def get_session() -> AsyncGenerator[AsyncSession | Any, Any]:\n    async with SessionLocal() as session:\n        yield session\n\nasync def ensure_database():\n    """Creates the target database if it doesn\'t exist by connecting via the \'postgres\' DB."""\n    # connect to the admin DB to create the target DB\n    admin_url = db_url.set(database="postgres")\n    admin_engine = create_async_engine(admin_url, isolation_level="AUTOCOMMIT", pool_pre_ping=True)\n    try:\n        async with admin_engine.begin() as conn:\n            exists = await conn.scalar(\n                text("SELECT 1 FROM pg_database WHERE datname = :name"),\n                {"name": settings.DB_NAME},\n            )\n            if not exists:\n                await conn.execute(text(f\'CREATE DATABASE "{settings.DB_NAME}"\'))\n                logger.info(f\'Created database "{settings.DB_NAME}".\')\n    finally:\n        await admin_engine.dispose()\n\nasync def ensure_extensions():\n    """Installs required PostgreSQL extensions (e.g., \'vector\') in the target database."""\n    async with engine.begin() as conn:\n        # Install pgvector extension; requires superuser or appropriate privs\n        await conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))\n        logger.info("Ensured extension: vector")\n\nasync def create_tables():\n    """Drops and recreates the database tables based on the SQLAlchemy ORM models."""\n    async with engine.begin() as conn:\n        await conn.run_sync(mapper_registry.metadata.drop_all)\n        await conn.run_sync(mapper_registry.metadata.create_all)\n\n\ndef chunked(iterable: list, n: int) -> list:\n    """Yields successive n-sized chunks from a list."""\n    for i in range(0, len(iterable), n):\n        yield iterable[i:i+n]\n\nasync def populate_db(chunk_size: int = 2000):\n    """Populates the database with recipes and their embeddings from the Parquet file.\n\n    Args:\n        chunk_size: The number of rows to insert in each bulk operation.\n    """\n    df = pd.read_parquet(EMBEDDING_DATASET_FILE, engine="pyarrow")\n\n    # Build payload rows\n    rows = []\n    for _, r in df.iterrows():\n        rows.append({\n            "recipe_name":      r.get("recipe_name"),\n            "description":      r.get("description"),\n            "ingredients":      ",".join(r.get("ingredients").strip("[]").replace("\'", "").split(",")),\n            "time_minutes":     r.get("time_minutes"),\n            "preparation":      r.get("preparation"),\n            "country":          r.get("country"),\n            "gemini_embedding": r.get("gemini_embedding"),  # list[float] \u2014 pgvector will handle it\n            "gemma_embedding":  r.get("gemma_embedding"),   # list[float] \u2014 pgvector will handle it\n        })\n    # Fast bulk insert in chunks\n    async with SessionLocal() as session:\n        stmt = insert(RecipeORM)\n        for chunk in chunked(rows, chunk_size):\n            async with session.begin():\n                await session.execute(stmt, chunk)\n\n\nasync def create_indexes():\n  """Creates IVFFlat indexes on the embedding columns for faster similarity searches."""\n  async with engine.begin() as conn:\n    await conn.execute(text("CREATE INDEX IF NOT EXISTS idx_gemini_embedding_cosine ON recipes USING ivfflat (gemini_embedding vector_cosine_ops) WITH (lists = 100)"))\n    await conn.execute(text("CREATE INDEX IF NOT EXISTS idx_gemma_embedding_cosine ON recipes USING ivfflat (gemma_embedding vector_cosine_ops) WITH (lists = 100)"))\n    logger.info("Created indexes on embeddings.")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"4-query-the-rag-system",children:"4. Query the RAG System"}),"\n",(0,s.jsx)(n.p,{children:"At this point, our embeddings are stored in PostgreSQL with pgvector, and we\u2019re ready to query the system. This is where retrieval comes into play: instead of searching by keywords, we transform a user query into an embedding and perform a similarity search against our stored recipe vectors. The result is a set of semantically relevant matches, even if the exact keywords don\u2019t appear in the text."}),"\n",(0,s.jsx)(n.p,{children:"For example:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["A query like ",(0,s.jsx)(n.em,{children:"\u201cquick Mexican dishes under 20 minutes\u201d"})," might return tacos, quesadillas, or salsas\u2014even if the word ",(0,s.jsx)(n.em,{children:"\u201cquick\u201d"})," is not explicitly mentioned in the recipe title."]}),"\n",(0,s.jsxs)(n.li,{children:["A query for ",(0,s.jsx)(n.em,{children:"\u201csoups with root vegetables\u201d"})," would surface carrot, potato, or cassava-based soups, even when the exact phrase ",(0,s.jsx)(n.em,{children:"\u201croot vegetables\u201d"})," is missing."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Querying with Gemma and Gemini"})}),"\n",(0,s.jsx)(n.p,{children:"We define two query functions: one that uses Gemma embeddings and one that uses Gemini embeddings. Both follow the same high-level steps:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Encode the user query into an embedding."}),"\n",(0,s.jsx)(n.li,{children:"Normalize the embedding for cosine similarity (For Gemini only)"}),"\n",(0,s.jsx)(n.li,{children:"Run a SQLAlchemy query that leverages pgvector\u2019s cosine_distance function."}),"\n",(0,s.jsx)(n.li,{children:"Filter results by similarity threshold."}),"\n",(0,s.jsx)(n.li,{children:"Return the top matches, ordered by distance."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Gemma-based query:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'\n@timeit\nasync def query_gemma(query: str, limit: int = 5, similarity_threshold: float = 0.7) -> Sequence[\n    Row[tuple[RecipeORM, Any]]]:\n    """Queries the database for recipes similar to the input query using Gemma embeddings.\n\n    Args:\n        query: The search query string.\n        limit: The maximum number of results to return.\n        similarity_threshold: The maximum cosine distance for a result to be included.\n                              A lower value means higher similarity.\n\n    Returns:\n        A list of tuples, where each tuple contains a RecipeORM object and its distance.\n    """\n    model_id = kagglehub.model_download(GEMMA_EMBEDDING_MODEL)\n    device = "cuda" if torch.cuda.is_available() else "cpu"\n    model = SentenceTransformer(model_id).to(device=device)\n\n    async with SessionLocal() as session:\n        query_embedding = model.encode(\n            query,\n            prompt_name="Retrieval-query"\n        )\n        select_expr = RecipeORM.gemma_embedding.cosine_distance(query_embedding).label("distance")\n        stmt = (\n            select(RecipeORM, select_expr)\n            .where(select_expr < similarity_threshold)  # keep only close neighbors\n            .order_by(select_expr.asc())                # smallest distance = most similar\n            .limit(limit)\n        )\n\n        result = await session.execute(stmt)\n        rows = result.all()  # list[tuple[RecipeORM, float]]\n\n        # Example: print or return structured data\n        for recipe, dist in rows:\n            logger.info(f"Recipe: {recipe.recipe_name}, Country: {recipe.country}, Time: {recipe.time_minutes} mins, Distance: {dist:.4f}")\n\n        return rows\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Gemini-based query:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'@timeit\nasync def query_gemini(query: str, limit: int = 5, similarity_threshold: float = 0.7) -> Sequence[\n    Row[tuple[RecipeORM, Any]]]:\n    """Queries the database for recipes similar to the input query using Gemini embeddings.\n\n    Args:\n        query: The search query string.\n        limit: The maximum number of results to return.\n        similarity_threshold: The maximum cosine distance for a result to be included.\n                              A lower value means higher similarity.\n\n    Returns:\n        A list of tuples, where each tuple contains a RecipeORM object and its distance.\n    """\n    result = client.models.embed_content(\n        model=GEMINI_EMBEDDING_MODEL,\n        contents=[types.Part.from_text(text=query)],\n        config=types.EmbedContentConfig(\n            task_type="RETRIEVAL_QUERY",\n            output_dimensionality=EMBED_DIM\n        )\n    )\n    async with SessionLocal() as session:\n        query_embedding = np.array(result.embeddings[0].values)\n        normed_embedding = query_embedding / np.linalg.norm(query_embedding)\n        logger.debug(f"Normed embedding length: {len(normed_embedding)}")\n        logger.debug(f"Norm of normed embedding: {np.linalg.norm(normed_embedding):.6f}")  # Should be very close to 1\n        select_expr = RecipeORM.gemini_embedding.cosine_distance(normed_embedding).label("distance")\n        stmt = (\n            select(RecipeORM, select_expr)\n            .where(select_expr < similarity_threshold)  # keep only close neighbors\n            .order_by(select_expr.asc())  # smallest distance = most similar\n            .limit(limit)\n        )\n\n        result = await session.execute(stmt)\n        rows = result.all()  # list[tuple[RecipeORM, float]]\n        # Example: print or return structured data\n        for recipe, dist in rows:\n            logger.info(\n                f"Recipe: {recipe.recipe_name}, Country: {recipe.country}, Time: {recipe.time_minutes} mins, Distance: {dist:.4f}")\n\n        return rows\n'})}),"\n",(0,s.jsx)(n.p,{children:"Both functions return a list of matching recipes along with their similarity scores. For each recipe, we log details such as:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Recipe name"}),"\n",(0,s.jsx)(n.li,{children:"Country of origin"}),"\n",(0,s.jsx)(n.li,{children:"Preparation time"}),"\n",(0,s.jsx)(n.li,{children:"Cosine distance (similarity)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Running a RAG Query"})}),"\n",(0,s.jsx)(n.p,{children:"Finally, we define a helper function that lets us test queries against both embeddings side by side:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def test_rag(query: str, limit: int = 5, similarity_threshold: float = 0.7) -> None:\n    """Runs a RAG query against both Gemma and Gemini embeddings and prints the results.\n\n    Args:\n        query: The search query string.\n        limit: The maximum number of results to return.\n        similarity_threshold: The cosine distance threshold for filtering results.\n    """\n    await query_gemma(query, limit, similarity_threshold)\n    await query_gemini(query, limit, similarity_threshold)\n'})}),"\n",(0,s.jsx)(n.p,{children:"With this function, we can run a semantic query like:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'await test_rag("Find quick South America dishes with corn", limit=5)\n'})}),"\n",(0,s.jsx)(n.p,{children:"Instead of relying on keyword matches, the system will return recipes that mean the same thing\u2014like tacos, esquites, or tamales\u2014even if \u201cquick\u201d or \u201ccorn\u201d aren\u2019t explicitly mentioned in the title."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Example Output"})}),"\n",(0,s.jsx)(n.p,{children:"Here\u2019s what the log output might look like when running the query above:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-terminaloutput",children:"INFO:__main__:Recipe: Arepas, Country: Venezuela, Time: 35 mins, Distance: 0.4425\nINFO:__main__:Recipe: Empanadas, Country: Argentina, Time: 75 mins, Distance: 0.5312\nINFO:__main__:Recipe: Cachupa, Country: Cape Verde, Time: 240 mins, Distance: 0.5497\nINFO:__main__:Recipe: Causa Rellena, Country: Peru, Time: 60 mins, Distance: 0.5565\nINFO:__main__:Recipe: Asado, Country: Argentina, Time: 180 mins, Distance: 0.5635\nINFO:__main__:query_gemma took 4.7631 seconds\n\nINFO:__main__:Recipe: Arepas, Country: Venezuela, Time: 35 mins, Distance: 0.2650\nINFO:__main__:Recipe: Cachupa, Country: Cape Verde, Time: 240 mins, Distance: 0.3252\nINFO:__main__:Recipe: Ceviche, Country: Peru, Time: 25 mins, Distance: 0.3319\nINFO:__main__:Recipe: Ugali, Country: Kenya, Time: 15 mins, Distance: 0.3347\nINFO:__main__:Recipe: Salte\xf1as, Country: Bolivia, Time: 240 mins, Distance: 0.3348\nINFO:__main__:query_gemini took 0.2211 seconds\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Why This Matters"})}),"\n",(0,s.jsx)(n.p,{children:"This retrieval layer is what makes our RAG system powerful. By grounding generation in semantically aligned recipes, we move well beyond keyword search and enable more flexible, accurate, and meaningful results."}),"\n",(0,s.jsx)(n.h2,{id:"5-visualizing-recipe-embeddings",children:"5. Visualizing Recipe Embeddings"}),"\n",(0,s.jsxs)(n.p,{children:["Once we\u2019ve built our RAG system and can query it effectively, the next natural step is to ",(0,s.jsx)(n.strong,{children:"visualize the embedding space"}),". Visualizations help us understand how recipes are clustered by similarity and whether our embeddings capture meaningful relationships between data points."]}),"\n",(0,s.jsxs)(n.p,{children:["To do this, we define a function ",(0,s.jsx)(n.code,{children:"plot_embeddings"})," that projects high-dimensional embeddings into ",(0,s.jsx)(n.strong,{children:"two dimensions"})," and generates an ",(0,s.jsx)(n.strong,{children:"interactive scatter plot"})," with Plotly. Each point represents a recipe, colored by country of origin, with recipe names displayed as labels."]}),"\n",(0,s.jsx)(n.h3,{id:"dimensionality-reduction",children:"Dimensionality Reduction"}),"\n",(0,s.jsx)(n.p,{children:"Embeddings typically have hundreds of dimensions, which are impossible to visualize directly. To make them interpretable, we reduce them into 2D using one of three methods:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"PCA"})," \u2013 a linear projection, fast and simple."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"t-SNE"})," \u2013 non-linear, great for local structure, works well on smaller datasets."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"UMAP (better suited for larger datasets)"})," \u2013 UMAP balances local and global structure, making it suitable for both small and large datasets"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["You can choose which method to apply by passing ",(0,s.jsx)(n.code,{children:'"pca"'}),", ",(0,s.jsx)(n.code,{children:'"tsne"'}),", or ",(0,s.jsx)(n.code,{children:'"umap"'})," to the function."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def plot_embeddings( # type: ignore\n        method: str = "tsne",\n        save_html_path: Optional[str] = "embeddings_plot.html",\n        random_state: int = 42,\n        perplexity: Optional[int] = None,\n        umap_neighbors: int = 15,\n        umap_min_dist: float = 0.1,\n):\n  """Creates an interactive 2D projection of recipe embeddings.\n\n  This function fetches embeddings from the database, reduces their dimensionality\n  using a specified method (PCA, t-SNE, or UMAP), and generates an interactive\n  scatter plot with Plotly, colored by country.\n\n  Args:\n      method: The dimensionality reduction technique (\'pca\', \'tsne\', or \'umap\').\n      save_html_path: Path to save the interactive HTML plot. If None, not saved.\n      random_state: Seed for reproducibility in t-SNE and UMAP.\n      perplexity: The perplexity for t-SNE. Auto-calculated if None.\n      umap_neighbors: The number of neighbors for UMAP.\n      umap_min_dist: The minimum distance for UMAP.\n  """\n  ...\n'})}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"Show Code"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def plot_embeddings( # type: ignore\n    method: str = "tsne",\n    save_html_path: Optional[str] = "embeddings_plot.html",\n    random_state: int = 42,\n    perplexity: Optional[int] = None,\n    umap_neighbors: int = 15,\n    umap_min_dist: float = 0.1,\n):\n    """Creates an interactive 2D projection of recipe embeddings.\n\n    This function fetches embeddings from the database, reduces their dimensionality\n    using a specified method (PCA, t-SNE, or UMAP), and generates an interactive\n    scatter plot with Plotly, colored by country.\n\n    Args:\n        method: The dimensionality reduction technique (\'pca\', \'tsne\', or \'umap\').\n        save_html_path: Path to save the interactive HTML plot. If None, not saved.\n        random_state: Seed for reproducibility in t-SNE and UMAP.\n        perplexity: The perplexity for t-SNE. Auto-calculated if None.\n        umap_neighbors: The number of neighbors for UMAP.\n        umap_min_dist: The minimum distance for UMAP.\n    """\n    method = method.lower()\n    if method not in {"pca", "tsne", "umap"}:\n        raise ValueError("method must be \'pca\', \'tsne\', or \'umap\'")\n\n    async with SessionLocal() as session:\n        query = select(\n            RecipeORM.gemini_embedding,  # Vector (list/array)\n            RecipeORM.country,          # Categorical label\n            RecipeORM.recipe_name       # For hover text\n        )\n        result = await session.execute(query)\n        rows = result.all()\n\n    if not rows:\n        raise RuntimeError("No rows found.")\n\n    # Convert to arrays/lists\n    X = np.array([np.array(r[0], dtype=np.float32) for r in rows])\n    countries = [r[1] for r in rows]\n    names = [r[2] for r in rows]\n\n\n    # Pick reducer\n    if method == "pca":\n        reducer = PCA(n_components=2, random_state=random_state)\n        projections = reducer.fit_transform(X)\n        subtitle = "PCA (linear)"\n    elif method == "tsne":\n        # Sensible perplexity defaults: must be < n_samples\n        n = len(X)\n        auto_perp = max(5, min(30, (n - 1) // 3))\n        perp = perplexity if perplexity is not None else auto_perp\n        perp = min(perp, max(5, n // 3 if n >= 6 else 5))\n        reducer = TSNE(\n            n_components=2,\n            perplexity=perp,\n            learning_rate="auto",\n            init="pca",\n            random_state=random_state,\n            n_iter_without_progress=300,\n            metric="cosine"\n        )\n        projections = reducer.fit_transform(X)\n        subtitle = f"t-SNE (perplexity={perp}, cosine metric)"\n    else:\n        reducer = umap.UMAP(\n            n_components=2,\n            n_neighbors=umap_neighbors,\n            min_dist=umap_min_dist,\n            metric="cosine",\n            random_state=random_state,\n        )\n        projections = reducer.fit_transform(X)\n        subtitle = f"UMAP (n_neighbors={umap_neighbors}, min_dist={umap_min_dist}, cosine metric)"\n\n    # Build interactive figure\n    df = {\n        "x": projections[:, 0],\n        "y": projections[:, 1],\n        "country": countries,\n        "name": names,\n        # Nice, readable hover text\n        "label": [f"<b>{nm}</b><br>Country: {cty}" for nm, cty in zip(names, countries)],\n    }\n\n    fig = px.scatter(\n        df,\n        x="x",\n        y="y",\n        color="country",\n        hover_name="name",\n        text="name",  # \ud83d\udc48 this keeps the recipe name always visible\n        labels={"x": "Component 1", "y": "Component 2"},\n        title=f"Recipe Embeddings \u2014 {subtitle}",\n        opacity=0.85\n    )\n\n    # Adjust text appearance\n    fig.update_traces(\n        textposition="top center",  # \'top center\', \'bottom right\', etc.\n        marker=dict(size=8, line=dict(width=0.5)),\n        hovertemplate="%{customdata[0]}<extra></extra>",\n        customdata=np.array([[lbl] for lbl in df["label"]]),\n    )\n\n\n    # Subtle layout polish\n    fig.update_layout(\n        legend_title_text="Country",\n        template="plotly_white",\n        margin=dict(l=40, r=40, t=60, b=40),\n        xaxis=dict(showgrid=True, zeroline=False),\n        yaxis=dict(showgrid=True, zeroline=False),\n    )\n\n    # Optional: save sharable HTML\n    if save_html_path:\n        fig.write_html(save_html_path, include_plotlyjs="cdn")\n\n    return fig\n'})})]}),"\n",(0,s.jsx)(n.h3,{id:"interactive-plot",children:"Interactive Plot"}),"\n",(0,s.jsx)(n.p,{children:"The function pulls embeddings, recipe names, and countries from the database, applies the chosen dimensionality reduction, and builds an interactive Plotly scatter plot."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Color"}),": Recipes are colored by country."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Hover text"}),": Displays the recipe name and country."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Labels"}),": Recipe names are shown directly on the plot for easy exploration."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The result is an HTML file you can open in your browser and explore. For example, clusters of recipes from the same country often appear close together, while recipes with similar ingredients may form cross-country overlaps."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'fig = px.scatter(\n    df,\n    x="x",\n    y="y",\n    color="country",\n    hover_name="name",\n    text="name",\n    title=f"Recipe Embeddings \u2014 {subtitle}",\n    opacity=0.85\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:"Visualizing embeddings gives us intuition about how well the model organizes recipes. If Mexican soups cluster together, or Italian pasta dishes appear in the same region of the plot, it\u2019s a sign that the embeddings are capturing meaningful semantic structure.\nBy exploring these visualizations, we can validate whether our embeddings align with human intuition\u2014and gain confidence in using them to power retrieval in our RAG pipeline."}),"\n",(0,s.jsx)(n.h2,{id:"bonus-automating-synthetic-data-generation-with-a-multi-agent-architecture",children:"Bonus: Automating Synthetic Data Generation with a Multi-Agent Architecture"}),"\n",(0,s.jsxs)(n.p,{children:["So far, we\u2019ve generated recipes directly through prompts. As a bonus, let\u2019s take it one step further and see how a ",(0,s.jsx)(n.strong,{children:"multi-agent system"})," can automate this process. Using ",(0,s.jsx)(n.strong,{children:"Google ADK"}),", we can orchestrate multiple agents that collaborate to create diverse, structured recipes\u2014ready to use in our RAG pipeline."]}),"\n",(0,s.jsx)(n.h3,{id:"the-idea",children:"The Idea"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["A ",(0,s.jsx)(n.strong,{children:"Root Agent"})," acts as the \u201chead chef,\u201d coordinating recipe generation."]}),"\n",(0,s.jsxs)(n.li,{children:["A ",(0,s.jsx)(n.strong,{children:"Search Agent"})," supports the Root Agent by performing Google searches when extra context is needed."]}),"\n",(0,s.jsxs)(n.li,{children:["Recipes are returned in a ",(0,s.jsx)(n.strong,{children:"structured format"})," defined by a Pydantic schema, ensuring clean, machine-readable outputs."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"workflow-overview-1",children:"Workflow Overview"}),"\n",(0,s.jsx)(n.p,{children:"Here\u2019s how the agents interact to generate recipes automatically:"}),"\n",(0,s.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant U as User\n    participant R as Root Agent\n    participant S as Search Agent\n    participant DB as Schema (RecipeList)\n    U->>R: Request 200 recipes from different countries\n    R->>S: (Optional) Perform Google Search for authentic recipes\n    S--\x3e>R: Return search results\n    R->>DB: Generate structured recipe data (RecipeList)\n    DB--\x3e>R: Validated recipes\n    R--\x3e>U: Return final JSON/Excel dataset"}),"\n",(0,s.jsx)(n.h3,{id:"core-components",children:"Core Components"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Structure Outputs"}),"\nRecipes are modeled with Pydantic, including fields like ",(0,s.jsx)(n.code,{children:"recipe_name"}),", ",(0,s.jsx)(n.code,{children:"description"}),", ",(0,s.jsx)(n.code,{children:"ingredients"}),", ",(0,s.jsx)(n.code,{children:"preparation"}),", ",(0,s.jsx)(n.code,{children:"time_minutes"}),", and ",(0,s.jsx)(n.code,{children:"country"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Root Agent"}),"\nCoordinates the request, ensures diversity, and outputs recipes in schema-compliant JSON."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Search Agent"}),"\nProvides external knowledge via Google Search when needed."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Runner & Session Management"}),"\nUses ",(0,s.jsx)(n.code,{children:"InMemoryRunner"})," to manage sessions and stream responses asynchronously."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Exporting Results"}),"\nRecipes are validated, stored in a Pandas DataFrame, and exported to Excel for downstream tasks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"example-running-the-pipeline",children:"Example: Running the Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def main():\n    user_request = "I would like to get 200 recipes from different countries."\n    response = await call_agent_async(root_agent, user_request)\n\n    try:\n        response_data = RecipeList.model_validate_json(response)\n        print(f"Final Response: {len(response_data.recipes)} recipes generated")\n        recipes_to_excel(response_data.recipes, "generated_recipes.xlsx")\n    except Exception as e:\n        print("Failed to parse response:", e)\n        print("Raw response:", response)\n'})}),"\n",(0,s.jsx)(n.p,{children:"Running this pipeline automatically produces a diverse set of recipes and saves them in an Excel file\u2014all without manual curation."}),"\n",(0,s.jsx)(n.p,{children:"Here is the full code for the multiagent architecture:"}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"Show Code"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import os\nimport uuid\nimport asyncio\nfrom typing import Optional\n\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel\n\nfrom google.adk.agents import BaseAgent\nfrom google.adk.agents.llm_agent import Agent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import google_search, AgentTool\nfrom google.genai import types\nimport pandas as pd\nfrom typing import List\nfrom pathlib import Path\n\n# Load environment variables from .env if present\nload_dotenv()\n\nAPP_NAME = "RecipeGeneratorApp"\nROOT_AGENT_INSTRUCTION = """\nYou are a world-class international chef and culinary researcher.  \nYour goal is to help users discover authentic recipes from around the world.  \nYou can use the Google Search tool if needed to find recipes.\n\nFollow these instructions carefully:  \n1. Ask the user how many recipes they would like you to generate and store this number as **n**.  \n2. Collect or search for **n diverse recipes** representing different countries and cuisines.  \n3. For each recipe, provide the following fields:  \n   - recipe_name (short, descriptive title)  \n   - description (1\u20132 sentences highlighting uniqueness or flavor)  \n   - ingredients (list of core ingredients only, no steps)  \n   - time_minutes (estimated preparation time as an integer)  \n   - preparation (brief summary of preparation method)\n   - country (country or region of origin)  \n4. Return the final list of recipes as a JSON array strictly following the `RecipeList` output schema.  \n\nImportant:\nDont prompt the user for more information than the number of recipes, and return only the list of recipes in the final response.\n\nKeep your answers concise, authentic, and well-formatted.  \nDo not include fields outside the schema, or add extra commentary.  \n"""\n\n\nclass Recipe(BaseModel):\n    recipe_name: str\n    description: str\n    ingredients: list[str]\n    preparation: str\n    time_minutes: int\n    country: str\n\n\nclass RecipeList(BaseModel):\n    recipes: list[Recipe]\n\n\nsearch_agent = Agent(\n    model="gemini-2.0-flash",\n    name="SearchAgent",\n    instruction="You are a specialist in Google Search.",\n    tools=[google_search],\n)\n\nroot_agent = Agent(\n    model="gemini-2.5-flash",\n    name="RootAgent",\n    description="A helpful assistant that generates synthetic recipes.",\n    output_schema=RecipeList,\n    output_key="recipes",\n    tools=[AgentTool(search_agent)],\n    disallow_transfer_to_parent=True,\n    disallow_transfer_to_peers=True,\n    instruction=ROOT_AGENT_INSTRUCTION\n)\n\n\n\nasync def call_agent_async(\n    agent: BaseAgent,\n    request: str,\n    user_id: Optional[str] = None,\n    session_id: Optional[str] = None,\n    initial_state: Optional[dict] = None,\n) -> str:\n    """\n    Run the given agent asynchronously and return its final response text.\n    """\n    user_id = user_id or str(uuid.uuid4())\n    session_id = session_id or str(uuid.uuid4())\n\n    runner = InMemoryRunner(agent=agent, app_name=APP_NAME)\n\n    # Ensure a session exists (idempotent create ok)\n    await runner.session_service.create_session(\n        app_name=APP_NAME,\n        user_id=user_id,\n        session_id=session_id,\n        state=initial_state,\n    )\n\n    # Create user content message\n    content = types.Content(role="user", parts=[types.Part(text=request)])\n\n    final_response_text: Optional[str] = None\n\n    # Run the agent and stream events\n    async for event in runner.run_async(\n        user_id=user_id, session_id=session_id, new_message=content\n    ):\n        if event.is_final_response():\n            if event.content and event.content.parts:\n                final_response_text = event.content.parts[0].text\n            elif getattr(event, "actions", None) and getattr(event.actions, "escalate", None):\n                final_response_text = (\n                    f"Agent escalated: {event.error_message or \'No specific message.\'}"\n                )\n\n    return final_response_text or ""\n\n\ndef recipes_to_excel(recipes: List, filename: str = "recipes.xlsx") -> Path:\n    """\n    Convert a list of Pydantic Recipe objects into a pandas DataFrame\n    and export it to an Excel file.\n\n    Args:\n        recipes (List[Recipe]): List of Pydantic Recipe objects.\n        filename (str): Output Excel file name. Defaults to \'recipes.xlsx\'.\n\n    Returns:\n        Path: Path to the generated Excel file.\n    """\n    # Convert Pydantic objects into dicts\n    data = [r.model_dump() for r in recipes]\n\n    # Create DataFrame\n    df = pd.DataFrame(data)\n\n    # Export to Excel\n    output_path = Path(filename).resolve()\n    df.to_excel(output_path, index=False, engine="openpyxl")\n\n    print(f"Exported {len(df)} recipes to {output_path}")\n    return output_path\n\n\nasync def main():\n    user_request = "I would like to get 200 recipes from different countries."\n    response = await call_agent_async(root_agent, user_request)\n\n    try:\n        response_data = RecipeList.model_validate_json(response)\n        print(f"Final Response: {len(response_data.recipes)} recipes generated")\n        recipes_to_excel(response_data.recipes, "generated_recipes.xlsx")\n    except Exception as e:\n        print("Failed to parse response:", e)\n        print("Raw response:", response)\n\n\nif __name__ == "__main__":\n    asyncio.run(main())\n'})})]}),"\n",(0,s.jsx)(n.h2,{id:"conclusion--closing-remarks",children:"Conclusion & Closing Remarks"}),"\n",(0,s.jsxs)(n.p,{children:["We\u2019ve just walked through building a ",(0,s.jsx)(n.strong,{children:"recipe-focused RAG pipeline"})," from start to finish: generating a synthetic dataset, creating embeddings with Gemini and Gemma, storing them in PostgreSQL with pgvector, running semantic queries, and even visualizing the embedding space. Along the way, we saw how moving beyond keyword search unlocks richer, more flexible ways to interact with data."]}),"\n",(0,s.jsx)(n.p,{children:"The recipe domain was a fun, concrete example\u2014but the same principles apply across many fields: document retrieval, customer support, scientific research, and beyond. Anywhere you need to ground generative models in reliable, semantically relevant information, this workflow is a strong foundation."}),"\n",(0,s.jsx)(n.p,{children:"If you\u2019ve followed along, you now have:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["A working setup for storing and retrieving embeddings with ",(0,s.jsx)(n.strong,{children:"pgvector + SQLAlchemy"})]}),"\n",(0,s.jsxs)(n.li,{children:["Query functions that support ",(0,s.jsx)(n.strong,{children:"semantic similarity search"})]}),"\n",(0,s.jsx)(n.li,{children:"Visual tools to explore and validate your embeddings"}),"\n",(0,s.jsx)(n.li,{children:"A blueprint for extending RAG pipelines into your own projects"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Building systems like this isn\u2019t just about technology\u2014it\u2019s about creating tools that feel more natural, helpful, and trustworthy. And the best part? Once you\u2019ve set up the scaffolding, you can swap in different datasets, embeddings, or downstream tasks to adapt the pipeline to your needs."}),"\n",(0,s.jsxs)(n.p,{children:["Thanks for joining me on this walkthrough. I hope it gave you both the ",(0,s.jsx)(n.strong,{children:"practical steps"})," and the ",(0,s.jsx)(n.strong,{children:"intuition"})," for why embeddings + RAG matter. If you experiment with your own dataset\u2014recipes or otherwise\u2014I\u2019d love to hear what you discover."]}),"\n",(0,s.jsxs)(n.p,{children:["Here is the link to the full code of this tutorial: ",(0,s.jsx)(n.a,{href:"https://github.com/haruiz/RAG-experiments/tree/main/rag-with-postgresql",children:"RAG-experiments repository"})]}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://ai.google.dev/gemini-api/docs/embeddings",children:"Gemini API \u2013 Embeddings Documentation"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://ai.google.dev/gemma/docs/embeddinggemma",children:"EmbeddingGemma Model Overview"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/2205.13147",children:"Matryoshka Representation Learning (MRL)"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://huggingface.co/blog/matryoshka",children:"Hugging Face Blog \u2013 Introduction to Matryoshka Embedding Models"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/pgvector/pgvector",children:"pgvector Documentation"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.sqlalchemy.org/",children:"SQLAlchemy Documentation"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.sbert.net/",children:"Sentence Transformers"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://umap-learn.readthedocs.io/en/latest/",children:"UMAP: Uniform Manifold Approximation and Projection"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf",children:"t-SNE (Laurens van der Maaten & Geoffrey Hinton, 2008)"})}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(96540);const s={},r=i.createContext(s);function a(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:n},e.children)}},98955:e=>{e.exports=JSON.parse('{"permalink":"/blog/building-a-rag-system-with-postgresql-pgvector-sqlalchemy-gemma-gemini-embeddings","source":"@site/blog/2025-09-13-building-a-rag-system-with-postgrespgvector-+-gemmagemini-embeddings/index.mdx","title":"Building a RAG System with PostgreSQL, pgvector, SQLAlchemy, and Gemma/Gemini Embeddings","description":"In this post, we build a Retrieval-Augmented Generation (RAG) pipeline from the ground up. Starting with synthetic data generated by Gemini, we create embeddings with both Gemini and Gemma, store them in PostgreSQL with pgvector, and query them through SQLAlchemy. We also visualize the embedding space interactively to reveal semantic structure. Along the way, we demonstrate how semantic search goes beyond keywords and showcase a multi-agent system that automates dataset generation.","date":"2025-09-13T00:00:00.000Z","tags":[{"inline":true,"label":"RAG","permalink":"/blog/tags/rag"},{"inline":true,"label":"data-science","permalink":"/blog/tags/data-science"}],"readingTime":33.4,"hasTruncateMarker":true,"authors":[{"name":"Henry Ruiz","title":"Blog Author","url":"https://github.com/haruiz","imageURL":"https://github.com/haruiz.png","key":"haruiz","page":null}],"frontMatter":{"title":"Building a RAG System with PostgreSQL, pgvector, SQLAlchemy, and Gemma/Gemini Embeddings","slug":"building-a-rag-system-with-postgresql-pgvector-sqlalchemy-gemma-gemini-embeddings","description":"In this post, we build a Retrieval-Augmented Generation (RAG) pipeline from the ground up. Starting with synthetic data generated by Gemini, we create embeddings with both Gemini and Gemma, store them in PostgreSQL with pgvector, and query them through SQLAlchemy. We also visualize the embedding space interactively to reveal semantic structure. Along the way, we demonstrate how semantic search goes beyond keywords and showcase a multi-agent system that automates dataset generation.","authors":["haruiz"],"image":"https://haruiz.github.io/img/building-a-rag-system-with-postgresql-pgvector-sqlalchemy-gemma-gemini-embeddings.png","tags":["RAG","data-science"]},"unlisted":false,"nextItem":{"title":"Accelerating Science with JAX - Simulations, Physics, and Beyond","permalink":"/blog/accelerating-science-with-jax-simulations-physics-and-beyond"}}')}}]);